{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 831,
   "id": "fa4664f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 832,
   "id": "d0b90aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CHMM:\n",
    "    def __init__(self, num_states, unique_emissions):\n",
    "        self.num_states = num_states\n",
    "        self.emission_to_index_map = {char: idx for idx, char in enumerate(unique_emissions)}\n",
    "        self.num_emissions = len(unique_emissions)\n",
    "        # self.transition_probs = np.full((num_states, num_states), 1.0 / num_states)\n",
    "        # self.emission_probs = np.random.rand(num_states, self.num_emissions)\n",
    "\n",
    "        self.transition_probs = np.random.rand(num_states, num_states)\n",
    "        self.transition_probs /= self.transition_probs.sum(axis=1, keepdims=True)\n",
    "\n",
    "        # Initialize and normalize emission probabilities\n",
    "        self.emission_probs = np.random.rand(num_states, self.num_emissions)\n",
    "        self.emission_probs /= self.emission_probs.sum(axis=1, keepdims=True)\n",
    "\n",
    "    def observation_to_indices(self, observation):\n",
    "        indices = []\n",
    "        for emission in observation:\n",
    "            if emission in self.emission_to_index_map:\n",
    "                indices.append(self.emission_to_index_map[emission])\n",
    "            else:\n",
    "                raise ValueError(f\"Unexpected emission '{emission}' found in observation.\")\n",
    "                \n",
    "        return indices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 833,
   "id": "33758080",
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilon=1e-8\n",
    "def logsumexp(a):\n",
    "    \"\"\"Compute the log of the sum of exponentials of input elements.\"\"\"\n",
    "    a_max = np.max(a)\n",
    "    if a_max == -np.inf:\n",
    "        return -np.inf\n",
    "    return np.log(np.sum(np.exp(a - a_max))) + a_max\n",
    "\n",
    "def forward_pass(chmm, observation_indices):\n",
    "    \n",
    "    num_states = chmm.num_states\n",
    "    T = len(observation_indices)\n",
    "\n",
    "    # Initialize forward probabilities matrix\n",
    "    forward_probs = np.full((T, num_states), -np.inf)  # Use -np.inf for log(0)\n",
    "    \n",
    "    # Initial state probabilities (uniform)\n",
    "    forward_probs[0, :] = np.log(1.0 / num_states)\n",
    "\n",
    "    # Forward pass\n",
    "    for t in range(1, T):\n",
    "        for j in range(num_states):\n",
    "            emission_idx = observation_indices[t]\n",
    "            log_emission_prob = np.log(chmm.emission_probs[j, emission_idx] + epsilon)\n",
    "            log_trans_probs = np.log(chmm.transition_probs[:, j] + epsilon)\n",
    "            forward_probs[t, j] = logsumexp(forward_probs[t - 1, :] + log_trans_probs) + log_emission_prob\n",
    "\n",
    "    return forward_probs\n",
    "\n",
    "def backward_pass(chmm, observation_indices):\n",
    "    num_states = chmm.num_states\n",
    "    T = len(observation_indices)\n",
    "\n",
    "    # Initialize backward probabilities matrix\n",
    "    backward_probs = np.full((T, num_states), -np.inf)  # Use -np.inf for log(0)\n",
    "    backward_probs[T - 1, :] = 0  # log(1)\n",
    "\n",
    "    # Backward pass\n",
    "    for t in range(T - 2, -1, -1):\n",
    "        for i in range(num_states):\n",
    "            emission_idx = observation_indices[t + 1]\n",
    "            log_emission_probs = np.log(chmm.emission_probs[:, emission_idx] + epsilon)\n",
    "            log_trans_probs = np.log(chmm.transition_probs[i, :] + epsilon)\n",
    "            backward_probs[t, i] = logsumexp(backward_probs[t + 1, :] + log_trans_probs + log_emission_probs)\n",
    "\n",
    "    return backward_probs\n",
    "\n",
    "def forward_backward_algorithm(chmm, observation):\n",
    "    observation_indices = chmm.observation_to_indices(observation)\n",
    "    forward_probs = forward_pass(chmm, observation_indices)\n",
    "    backward_probs = backward_pass(chmm, observation_indices)\n",
    "\n",
    "    # Compute state probabilities at each time step\n",
    "    state_probs = np.exp(forward_probs + backward_probs)\n",
    "    state_probs /= np.sum(state_probs, axis=1, keepdims=True)  # Normalize\n",
    "\n",
    "    return state_probs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 834,
   "id": "9cdc19ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_nk(chmm, observation):\n",
    "    # Placeholder for calculating nk\n",
    "    return np.random.rand(chmm.num_states, chmm.num_emissions)  # Random counts\n",
    "\n",
    "def calculate_mk(chmm, observation, labels):\n",
    "    # Placeholder for calculating mk\n",
    "    return np.random.rand(chmm.num_states, chmm.num_emissions)  # Random counts\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 835,
   "id": "8627d10d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_theta(chmm, nk, mk, learning_rate, epsilon=1e-8):\n",
    "    for i in range(chmm.num_states):\n",
    "        for j in range(chmm.num_emissions):\n",
    "            theta_k = max(chmm.emission_probs[i][j], epsilon)\n",
    "            gradient = -(mk[i][j] - nk[i][j]) / theta_k\n",
    "            chmm.emission_probs[i][j] -= learning_rate * gradient\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 836,
   "id": "deb18dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_chmm(chmm, observation_label_pairs, learning_rate, num_iterations, batch_size, epsilon=1e-8):\n",
    "    for iteration in range(num_iterations):\n",
    "        np.random.shuffle(observation_label_pairs)\n",
    "        for i in range(0, len(observation_label_pairs), batch_size):\n",
    "            batch = observation_label_pairs[i:i + batch_size]\n",
    "            update_parameters_from_batch(chmm, batch, learning_rate, epsilon)\n",
    "\n",
    "def update_parameters_from_batch(chmm, batch, learning_rate, epsilon=1e-8):\n",
    "    batch_nk = []\n",
    "    batch_mk = []\n",
    "\n",
    "    for observation, labels in batch:\n",
    "        observation_indices = chmm.observation_to_indices(observation)\n",
    "        nk = calculate_nk(chmm, observation_indices)\n",
    "        mk = calculate_mk(chmm, observation_indices, labels)\n",
    "        batch_nk.append(nk)\n",
    "        batch_mk.append(mk)\n",
    "\n",
    "    # Average nk and mk over the batch\n",
    "    avg_nk = np.mean(batch_nk, axis=0)\n",
    "    avg_mk = np.mean(batch_mk, axis=0)\n",
    "\n",
    "    # Update model parameters\n",
    "    for i in range(chmm.num_states):\n",
    "        for j in range(chmm.num_emissions):\n",
    "            theta_k = max(chmm.emission_probs[i][j], epsilon)\n",
    "            gradient = -(avg_mk[i][j] - avg_nk[i][j]) / theta_k\n",
    "            chmm.emission_probs[i][j] -= learning_rate * gradient\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 837,
   "id": "e0a7ed28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_theta_sgd(chmm, avg_nk, avg_mk, learning_rate, epsilon=1e-8):\n",
    "    for i in range(chmm.num_states):\n",
    "        for j in range(chmm.num_emissions):\n",
    "            theta_k = max(chmm.emission_probs[i][j], epsilon)\n",
    "            gradient = -(avg_mk[i][j] - avg_nk[i][j]) / theta_k\n",
    "            chmm.emission_probs[i][j] -= learning_rate * gradient\n",
    "\n",
    "            \n",
    "def initialize_adam_parameters(chmm):\n",
    "    adam_params = {\n",
    "        \"m\": np.zeros((chmm.num_states, chmm.num_emissions)),\n",
    "        \"v\": np.zeros((chmm.num_states, chmm.num_emissions)),\n",
    "        \"t\": 0\n",
    "    }\n",
    "    return adam_params\n",
    "\n",
    "def update_theta_adam(chmm, avg_nk, avg_mk, learning_rate, adam_params, epsilon=1e-8, beta1=0.9, beta2=0.999):\n",
    "    adam_params[\"t\"] += 1\n",
    "    m = adam_params[\"m\"]\n",
    "    v = adam_params[\"v\"]\n",
    "    t = adam_params[\"t\"]\n",
    "    \n",
    "    for i in range(chmm.num_states):\n",
    "        for j in range(chmm.num_emissions):\n",
    "            theta_k = max(chmm.emission_probs[i][j], epsilon)\n",
    "            gradient = -(avg_mk[i][j] - avg_nk[i][j]) / theta_k\n",
    "            \n",
    "            # Update biased first moment estimate\n",
    "            m[i][j] = beta1 * m[i][j] + (1 - beta1) * gradient\n",
    "            \n",
    "            # Update biased second raw moment estimate\n",
    "            v[i][j] = beta2 * v[i][j] + (1 - beta2) * (gradient ** 2)\n",
    "            \n",
    "            # Compute bias-corrected first moment estimate\n",
    "            m_hat = m[i][j] / (1 - beta1 ** t)\n",
    "            \n",
    "            # Compute bias-corrected second raw moment estimate\n",
    "            v_hat = v[i][j] / (1 - beta2 ** t)\n",
    "            \n",
    "            # Update parameters\n",
    "            chmm.emission_probs[i][j] -= learning_rate * m_hat / (np.sqrt(v_hat) + epsilon)\n",
    "\n",
    "    adam_params[\"m\"] = m\n",
    "    adam_params[\"v\"] = v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 838,
   "id": "a1834a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def read_sequences(file_path):\n",
    "    \"\"\"\n",
    "    Read sequences and labels from a file.\n",
    "    The file format is expected to have the sequence and its labels on alternating lines.\n",
    "    \"\"\"\n",
    "    sequences = []\n",
    "    labels = []\n",
    "\n",
    "    with open(file_path, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "\n",
    "    for i in range(0, len(lines), 2):\n",
    "        sequence = lines[i].strip()\n",
    "        label = lines[i+1].strip()\n",
    "        sequences.append(sequence)\n",
    "        labels.append(label)\n",
    "\n",
    "    return sequences, labels\n",
    "\n",
    "def viterbi(chmm, observation_indices):\n",
    "    num_states = chmm.num_states\n",
    "    T = len(observation_indices)\n",
    "\n",
    "    # Initialize the Viterbi matrix with -infinity\n",
    "    viterbi_matrix = np.full((T, num_states), -np.inf)\n",
    "    backpointer_matrix = np.zeros((T, num_states), dtype=int)\n",
    "\n",
    "    # Initial state probabilities (log)\n",
    "    viterbi_matrix[0, :] = np.log(1.0 / num_states)\n",
    "\n",
    "    # Viterbi algorithm\n",
    "    for t in range(1, T):\n",
    "        for j in range(num_states):\n",
    "            emission_idx = observation_indices[t]\n",
    "            log_emission_prob = np.log(chmm.emission_probs[j, emission_idx] + epsilon)\n",
    "            log_trans_probs = np.log(chmm.transition_probs[:, j] + epsilon)\n",
    "            \n",
    "            # Calculate the maximum probability for each state\n",
    "            viterbi_matrix[t, j] = np.max(viterbi_matrix[t - 1, :] + log_trans_probs) + log_emission_prob\n",
    "            backpointer_matrix[t, j] = np.argmax(viterbi_matrix[t - 1, :] + log_trans_probs)\n",
    "\n",
    "    # Backtrack to find the most probable state sequence\n",
    "    best_path = np.zeros(T, dtype=int)\n",
    "    best_path[T - 1] = np.argmax(viterbi_matrix[T - 1, :])\n",
    "    for t in range(T - 2, -1, -1):\n",
    "        best_path[t] = backpointer_matrix[t + 1, best_path[t + 1]]\n",
    "\n",
    "    return best_path\n",
    "\n",
    "def calculate_accuracy(chmm, sequences, labels):\n",
    "    total_correct = 0\n",
    "    total_length = 0\n",
    "\n",
    "    for sequence, label_seq in zip(sequences, labels):\n",
    "        observation_indices = chmm.observation_to_indices(sequence)\n",
    "        label_seq = [int(label) for label in label_seq]  # Convert label sequence to integers\n",
    "        predicted_states = viterbi(chmm, observation_indices)\n",
    "\n",
    "        # Count the number of correct predictions in the sequence\n",
    "        correct_predictions = sum(p == l for p, l in zip(predicted_states, label_seq))\n",
    "        total_correct += correct_predictions\n",
    "        total_length += len(label_seq)\n",
    "\n",
    "    # Calculate the average accuracy across all sequences\n",
    "    if total_length == 0:\n",
    "        return 0  # Avoid division by zero\n",
    "    return (total_correct / total_length) * 100\n",
    "\n",
    "def train_and_validate_chmm(training_file, validation_file, num_states, unique_emissions, learning_rate, num_iterations, batch_size, epsilon=1e-8):\n",
    "    # Initialize CHMM\n",
    "    chmm = CHMM(num_states, unique_emissions)\n",
    "\n",
    "    # Read training data\n",
    "    training_sequences, training_labels = read_sequences(training_file)\n",
    "\n",
    "    # Prepare training data pairs\n",
    "    training_pairs = list(zip(training_sequences, training_labels))\n",
    "\n",
    "    # Train the CHMM\n",
    "    train_chmm(chmm, training_pairs, learning_rate, num_iterations, batch_size, epsilon)\n",
    "\n",
    "    # Read validation data\n",
    "    validation_sequences, validation_labels = read_sequences(validation_file)\n",
    "\n",
    "    # Evaluate on validation set\n",
    "    validation_prob = 0\n",
    "    for sequence, labels in zip(validation_sequences, validation_labels):\n",
    "        observation_indices = chmm.observation_to_indices(sequence)\n",
    "        forward_probs = forward_pass(chmm, observation_indices)\n",
    "        # Calculate the log probability of the sequence\n",
    "        log_prob = logsumexp(forward_probs[-1])\n",
    "        validation_prob += np.exp(log_prob)\n",
    "\n",
    "    # Average validation probability\n",
    "    validation_prob /= len(validation_sequences)\n",
    "\n",
    "    accuracy = calculate_accuracy(chmm, validation_sequences, validation_labels)\n",
    "\n",
    "    return validation_prob, accuracy\n",
    "\n",
    "# Example usage:\n",
    "# validation_probability = train_and_validate_chmm('training_data.txt', 'validation_data.txt', num_states, unique_emissions, learning_rate, num_iterations, batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 839,
   "id": "800f9fc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/n8/twgrw7857qg4trdvvmrx9ch80000gn/T/ipykernel_17024/1787187648.py:24: RuntimeWarning: invalid value encountered in divide\n",
      "  nk_transition /= np.sum(nk_transition)\n",
      "/var/folders/n8/twgrw7857qg4trdvvmrx9ch80000gn/T/ipykernel_17024/1787187648.py:25: RuntimeWarning: invalid value encountered in divide\n",
      "  nk_emission /= np.sum(nk_emission)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence. The requested array has an inhomogeneous shape after 3 dimensions. The detected shape was (20, 2, 4) + inhomogeneous part.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[839], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m unique_emissions \u001b[39m=\u001b[39m [\u001b[39m'\u001b[39m\u001b[39mA\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mR\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mN\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mD\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mC\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mQ\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mE\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mG\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mH\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mI\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mL\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mK\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mM\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mF\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mP\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mS\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mT\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mW\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mY\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mV\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m----> 3\u001b[0m validation_probability, accuracy \u001b[39m=\u001b[39m train_and_validate_chmm(\u001b[39m'\u001b[39;49m\u001b[39mHUMAN_training_data.txt\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mHUMAN_test_sequence.txt\u001b[39;49m\u001b[39m'\u001b[39;49m, num_states\u001b[39m=\u001b[39;49m\u001b[39m4\u001b[39;49m, unique_emissions\u001b[39m=\u001b[39;49munique_emissions, learning_rate\u001b[39m=\u001b[39;49m\u001b[39m0.0001\u001b[39;49m, num_iterations\u001b[39m=\u001b[39;49m\u001b[39m100\u001b[39;49m, batch_size\u001b[39m=\u001b[39;49m\u001b[39m20\u001b[39;49m)\n\u001b[1;32m      4\u001b[0m \u001b[39mprint\u001b[39m(validation_probability)\n\u001b[1;32m      5\u001b[0m \u001b[39mprint\u001b[39m(accuracy)\n",
      "Cell \u001b[0;32mIn[838], line 80\u001b[0m, in \u001b[0;36mtrain_and_validate_chmm\u001b[0;34m(training_file, validation_file, num_states, unique_emissions, learning_rate, num_iterations, batch_size, epsilon)\u001b[0m\n\u001b[1;32m     77\u001b[0m training_pairs \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(\u001b[39mzip\u001b[39m(training_sequences, training_labels))\n\u001b[1;32m     79\u001b[0m \u001b[39m# Train the CHMM\u001b[39;00m\n\u001b[0;32m---> 80\u001b[0m train_chmm(chmm, training_pairs, learning_rate, num_iterations, batch_size, epsilon)\n\u001b[1;32m     82\u001b[0m \u001b[39m# Read validation data\u001b[39;00m\n\u001b[1;32m     83\u001b[0m validation_sequences, validation_labels \u001b[39m=\u001b[39m read_sequences(validation_file)\n",
      "Cell \u001b[0;32mIn[836], line 6\u001b[0m, in \u001b[0;36mtrain_chmm\u001b[0;34m(chmm, observation_label_pairs, learning_rate, num_iterations, batch_size, epsilon)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m0\u001b[39m, \u001b[39mlen\u001b[39m(observation_label_pairs), batch_size):\n\u001b[1;32m      5\u001b[0m     batch \u001b[39m=\u001b[39m observation_label_pairs[i:i \u001b[39m+\u001b[39m batch_size]\n\u001b[0;32m----> 6\u001b[0m     update_parameters_from_batch(chmm, batch, learning_rate, epsilon)\n",
      "Cell \u001b[0;32mIn[836], line 20\u001b[0m, in \u001b[0;36mupdate_parameters_from_batch\u001b[0;34m(chmm, batch, learning_rate, epsilon)\u001b[0m\n\u001b[1;32m     17\u001b[0m     batch_mk\u001b[39m.\u001b[39mappend(mk)\n\u001b[1;32m     19\u001b[0m \u001b[39m# Average nk and mk over the batch\u001b[39;00m\n\u001b[0;32m---> 20\u001b[0m avg_nk \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mmean(batch_nk, axis\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m)\n\u001b[1;32m     21\u001b[0m avg_mk \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mmean(batch_mk, axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[1;32m     23\u001b[0m \u001b[39m# Update model parameters\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/numpy/core/fromnumeric.py:3504\u001b[0m, in \u001b[0;36mmean\u001b[0;34m(a, axis, dtype, out, keepdims, where)\u001b[0m\n\u001b[1;32m   3501\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   3502\u001b[0m         \u001b[39mreturn\u001b[39;00m mean(axis\u001b[39m=\u001b[39maxis, dtype\u001b[39m=\u001b[39mdtype, out\u001b[39m=\u001b[39mout, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m-> 3504\u001b[0m \u001b[39mreturn\u001b[39;00m _methods\u001b[39m.\u001b[39;49m_mean(a, axis\u001b[39m=\u001b[39;49maxis, dtype\u001b[39m=\u001b[39;49mdtype,\n\u001b[1;32m   3505\u001b[0m                       out\u001b[39m=\u001b[39;49mout, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/numpy/core/_methods.py:102\u001b[0m, in \u001b[0;36m_mean\u001b[0;34m(a, axis, dtype, out, keepdims, where)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_mean\u001b[39m(a, axis\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, dtype\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, out\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, keepdims\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, \u001b[39m*\u001b[39m, where\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m):\n\u001b[0;32m--> 102\u001b[0m     arr \u001b[39m=\u001b[39m asanyarray(a)\n\u001b[1;32m    104\u001b[0m     is_float16_result \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m    106\u001b[0m     rcount \u001b[39m=\u001b[39m _count_reduce_items(arr, axis, keepdims\u001b[39m=\u001b[39mkeepdims, where\u001b[39m=\u001b[39mwhere)\n",
      "\u001b[0;31mValueError\u001b[0m: setting an array element with a sequence. The requested array has an inhomogeneous shape after 3 dimensions. The detected shape was (20, 2, 4) + inhomogeneous part."
     ]
    }
   ],
   "source": [
    "\n",
    "unique_emissions = ['A', 'R', 'N', 'D', 'C', 'Q', 'E', 'G', 'H', 'I', 'L', 'K', 'M', 'F', 'P', 'S', 'T', 'W', 'Y', 'V']\n",
    "\n",
    "validation_probability, accuracy = train_and_validate_chmm('HUMAN_training_data.txt', 'HUMAN_test_sequence.txt', num_states=4, unique_emissions=unique_emissions, learning_rate=0.0001, num_iterations=100, batch_size=20)\n",
    "print(validation_probability)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "496964bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65fa56d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f41e8b9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
